{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAHWMYJv4xuc"
   },
   "source": [
    "# INF8225 TP1 H25 (v2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV-6EDgXO-S9"
   },
   "source": [
    "Prénom - NOM / Matricule ########\n",
    "\n",
    "Partie 3 réalisée: [seul(e)]\n",
    "ou avec\n",
    "[Prénom - NOM -\n",
    "Matricule ########]\n",
    "\n",
    "Date limite :\n",
    "\n",
    "20h30 le 6 février 2025 (Partie 1 et 2)\n",
    "\n",
    "20h30 le 20 février 2025 (Partie 3)\n",
    "\n",
    "Remettez votre fichier Colab sur Moodle en 2 formats: **.pdf** ET **.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo2CPniBeytl"
   },
   "source": [
    "**Comment utiliser**:\n",
    "\n",
    "Il faut copier ce notebook dans vos dossiers pour avoir une version que vous pouvez modifier, voici deux façons de le faire:\n",
    "* File / Save a copy in Drive ...\n",
    "* File / Download .ipynb\n",
    "\n",
    "**Pour utiliser un GPU**\n",
    "\n",
    "Runtime / Change Runtime Type / Hardware Accelerator / GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCGh-NNm47Tk"
   },
   "source": [
    "# Partie 1 (16 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7tkIgu75Ccd"
   },
   "source": [
    "## Objectif\n",
    "L’objectif de la Partie 1 du travail pratique est de permettre à l’étudiant de se familiariser avec les réseaux Bayésiens et la librairie Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iongVT7XRegv"
   },
   "source": [
    "## Problème\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdKetLE0hVev"
   },
   "source": [
    "Considérons le réseau Bayésien ci-dessous.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1QCJSfYGLJVg2-0_BO8BEHCnMEDsHSR6k\" alt=\"bayes_net\" width=\"600\"/>\n",
    "\n",
    "Ceci représente un modèle simple pour les notes à un examen (G) et sa relation avec les étudiants qui se préparent aux examens et font correctement le travail pour les devoirs (S), les étudiants qui ont des difficultés dans la vie juste avant l'examen final (D), les étudiants qui réussissent bien à un entretien technique pour un emploi axé sur le sujet du cours (R), et des étudiants qui se retrouvent sur une sorte de palmarès de leur programme (L)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twz4slZ9DY6n"
   },
   "source": [
    "## Trucs et astuces\n",
    "Nous utiliserons des vecteurs multidimensionnels `5d-arrays` dont les `axes` représentent:\n",
    "```\n",
    "axe 0 : Se préparer (S)\n",
    "axe 1 : Difficultés avant l'exam (D)\n",
    "axe 2 : Réussir l'entretien technique (R)\n",
    "axe 3 : Note dans le cours (Grade) (G)\n",
    "axe 4 : Liste d'honneur (L)\n",
    "```\n",
    "\n",
    "Chaque `axe` serait de dimension `2` ou `3`:\n",
    "```\n",
    "Exemple pour S:\n",
    "0 : s0\n",
    "1 : s1\n",
    "\n",
    "Exemple pour G:\n",
    "0 : g0\n",
    "1 : g1\n",
    "2 : g2\n",
    "```\n",
    "Quelques point à garder en tête:\n",
    "- Utiliser la jointe comme point de départ pour vos calculs (ne pas développer tous les termes à la main).\n",
    "- Attention à l'effet du do-operator sur le graphe.\n",
    "- L'argument \"keepdims=True\" de \"np.sum()\" vous permet conserver les mêmes indices.\n",
    "- Pour un rappel sur les probabilités conditionelles, voir: https://www.probabilitycourse.com/chapter1/1_4_0_conditional_probability.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUjUNqVcTEXP"
   },
   "source": [
    "## 1. Complétez les tables de probabilités ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1738179837206,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "D-rxnQmCCCPa",
    "outputId": "ddfbb9fd-e31c-40ac-d2a5-eab1728d54e1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(S)=\n",
      "[0.2 0.8]\n",
      "\n",
      "Pr(D)=\n",
      "[0.9 0.1]\n",
      "\n",
      "Pr(R|S)=\n",
      "[[0.9 0.1]\n",
      " [0.2 0.8]]\n",
      "\n",
      "Pr(G|S,D)=\n",
      "[[[0.5  0.3  0.2 ]\n",
      "  [0.9  0.08 0.02]]\n",
      "\n",
      " [[0.1  0.2  0.7 ]\n",
      "  [0.3  0.4  0.3 ]]]\n",
      "\n",
      "Pr(L|G)=\n",
      "[[0.9  0.1 ]\n",
      " [0.6  0.4 ]\n",
      " [0.01 0.99]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "# Les tableaux sont bâtis avec les dimensions (S, D, R, G, L)\n",
    "# et chaque dimension avec les probablités associées aux 2 ou 3 valeurs possibles ({0, 1} ou {0, 1, 2})\n",
    "\n",
    "Pr_S = np.array([0.2, 0.8]).reshape(2, 1, 1, 1, 1) # Donné en exemple\n",
    "Pr_D = np.array([0.9, 0.1]).reshape(1, 2, 1, 1, 1) # TODO\n",
    "Pr_R_given_S = np.array([[0.9, 0.1] , [0.2 , 0.8]]).reshape(2, 1, 2, 1, 1) # TODO\n",
    "Pr_G_given_SD = np.array([[[0.5 , 0.3 , 0.2] , [0.9 , 0.08 , 0.02]] , [[0.1 , 0.2 , 0.7] , [0.3 , 0.4 , 0.3]]]).reshape(2, 2, 1, 3, 1) # TODO\n",
    "Pr_L_given_G =  np.array([[0.9, 0.1] , [0.6 , 0.4] , [0.01 , 0.99]] ).reshape(1, 1, 1, 3, 2)  # TODO\n",
    "\n",
    "print (f\"Pr(S)=\\n{np.squeeze(Pr_S)}\\n\")\n",
    "print (f\"Pr(D)=\\n{np.squeeze(Pr_D)}\\n\")\n",
    "print (f\"Pr(R|S)=\\n{np.squeeze(Pr_R_given_S)}\\n\")\n",
    "print (f\"Pr(G|S,D)=\\n{np.squeeze(Pr_G_given_SD)}\\n\")\n",
    "print (f\"Pr(L|G)=\\n{np.squeeze(Pr_L_given_G)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHD6DX-nS6Qt"
   },
   "source": [
    "## 2. À l'aide de ces tables de probabilité conditionnelles, calculez les requêtes ci-dessous. Dans les cas où l'on compare un calcul non interventionnel à un calcul interventionnel, commentez sur l'interprétation physique des deux situations et les résultats obtenus à partir de vos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-vXI0O279sX"
   },
   "source": [
    "a) $Pr(G) = [P (G = g^0), P (G = g^1), P (G = g^2)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1738111654513,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "lXWtZDsv791d",
    "outputId": "141e9f27-9a9d-470a-c09d-3cdfed9febde"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G)=[0.204  0.2316 0.5644]\n"
     ]
    }
   ],
   "source": [
    "joint  = Pr_G_given_SD * Pr_S * Pr_D* Pr_R_given_S * Pr_L_given_G\n",
    "answer_a = np.sum(joint, axis=(0, 1, 2 , 4)) # TODO\n",
    "print(f\"Pr(G)={answer_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738111654513,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "rtY9PF7spCQ4",
    "outputId": "bcea356c-87fa-4f61-cdd2-35be854e3f93"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "answer_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7fla36P79_G"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Ce texte est au format code\n",
    "```\n",
    "\n",
    "b) $Pr(G|R = r^1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738111654513,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "1Jp2AGLa7-H_",
    "outputId": "51d01b5d-0a6a-4a41-f0a9-eada7c7f51c2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G|R=r1)=[0.13273 0.22176 0.64552]\n"
     ]
    }
   ],
   "source": [
    "Pr_GR = np.sum(Pr_G_given_SD * Pr_R_given_S[:, :, 1:2, :, :] * Pr_S  * Pr_D, axis=(0, 1)) # TODO\n",
    "Pr_R = np.sum(\n",
    "    Pr_R_given_S[:, :, 1:2, :, :] * Pr_S,\n",
    "    axis=(0, 1, 2, 4)  # Somme sur S et les autres dimensions\n",
    ")\n",
    "answer_b = (Pr_GR / Pr_R).squeeze()\n",
    "print(f\"Pr(G|R=r1)={answer_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738111654513,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "Q3VEAVNY-oso",
    "outputId": "30ed3f20-c6a4-4371-c1a7-eaaf753611db"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G|R=r1)=[0.13273 0.22176 0.64552]\n"
     ]
    }
   ],
   "source": [
    "Pr_GR = np.sum(joint[: , : , 1:2 ,: ,:] , axis=(0,1,4))\n",
    "Pr_R = np.sum(joint[: , : , 1:2 ,: ,:] , axis=(0,1,3,4))\n",
    "answer_b = (Pr_GR / Pr_R).squeeze()\n",
    "print(f\"Pr(G|R=r1)={answer_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8mt03aX7-WC"
   },
   "source": [
    "c)  $Pr(G|R = r^0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1738111654754,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "nk_zBLQ7di_e",
    "outputId": "2f3b443b-6de0-4636-a3d9-989ac36a99a2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G|R=r0)=[0.34235 0.25071 0.40694]\n"
     ]
    }
   ],
   "source": [
    "Pr_GR = np.sum(joint[: , : , 0:1 ,: ,:] , axis=(0,1,4))\n",
    "Pr_R = np.sum(joint[: , : , 0:1 ,: ,:] , axis=(0,1,2,3,4))\n",
    "\n",
    "answer_c = (Pr_GR / Pr_R).squeeze()\n",
    "print(f\"Pr(G|R=r0)={answer_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSK8ulij7-m0"
   },
   "source": [
    "d) $Pr(G|R=r^1, S=s^0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738111654989,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "rKJL7JskHP8_",
    "outputId": "df8e0759-3ac6-4c44-ad4c-ccea8ae0cfd1"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3400000000000001"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "Pr_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738111654989,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "cliFsd8f7-vC",
    "outputId": "9692dad4-3553-4cfd-82d6-ac2e5d26a3be"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G|R=r1, S=s0)=[0.54  0.278 0.182]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "answer_d =  np.sum(Pr_G_given_SD[0:1  , : , : , : , :]  * Pr_S[0:1 , : , : , : , :]  * Pr_D, axis=(0, 1 , 2 , 4))/np.squeeze(Pr_S[0:1 , : , : , : , :])\n",
    "\n",
    "print(f\"Pr(G|R=r1, S=s0)={answer_d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1738111655216,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "cRyT4T0WF8tH",
    "outputId": "323f5724-6d30-47f9-c7f6-c22e085c7e4b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G|R=r1, S=s0)=[0.54  0.278 0.182]\n"
     ]
    }
   ],
   "source": [
    "Pr_GRS = np.sum(joint[0:1,:,1:2,:,:] , axis=(0,1,2,4))\n",
    "Pr_RS = np.sum(joint[0:1 , : , 1:2 ,: ,:] , axis=(0,1,2,3,4))\n",
    "answer_d =  (Pr_GRS / Pr_RS).squeeze()\n",
    "print(f\"Pr(G|R=r1, S=s0)={answer_d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDlylCAdtGE_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zffAAOW67-5I"
   },
   "source": [
    "e) $Pr(G|R=r^0, S=s^0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738111655773,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "9zyt7TeB7_CD",
    "outputId": "39115868-4ab0-4c67-b74f-7773081bc48b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G|R=r0, S=s0)=[4.86  2.502 1.638]\n"
     ]
    }
   ],
   "source": [
    "Pr_GRS = np.sum(joint[0:1,:,0:1,:,:] , axis=(0,1,2,4))\n",
    "Pr_RS = np.sum(joint[0:1 , : , 1:2 ,: ,:] , axis=(0,1,2,3,4))\n",
    "\n",
    "answer_e = (Pr_GRS / Pr_RS).squeeze()  # TODO\n",
    "print(f\"Pr(G|R=r0, S=s0)={answer_e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeIkZjn47_LZ"
   },
   "source": [
    "f) $Pr(R|D=d^1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1738111657056,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "Yscy5bf27_Sq",
    "outputId": "bbf6f7d9-f504-4f82-8d2b-56e4cc8bda17"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|D=d1)=[0.34 0.66]\n"
     ]
    }
   ],
   "source": [
    "Pr_RD =  np.sum(joint[:,1:2,:,:,:] , axis=(0,1,3,4))\n",
    "Pr_D1 =  np.sum(joint[:,1:2,:,: ,:] , axis=(0,1,2,3,4))\n",
    "answer_f = (Pr_RD / Pr_D1).squeeze()\n",
    "\n",
    "print(f\"Pr(R|D=d1)={answer_f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbV8cFjU8TxQ"
   },
   "source": [
    "g) $Pr(R|D=d^0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738111657495,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "7jBgoNDz8T6z",
    "outputId": "1fc2e383-8168-4b06-ae42-3122379485fc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|D=d0)=[0.34 0.66]\n"
     ]
    }
   ],
   "source": [
    "Pr_RD =  np.sum(joint[:,0:1,:,:,:] , axis=(0,1,3,4))\n",
    "Pr_D1 =  np.sum(joint[:,0:1,:,: ,:] , axis=(0,1,2,3,4))\n",
    "answer_g = (Pr_RD / Pr_D1).squeeze()   # TODO\n",
    "print(f\"Pr(R|D=d0)={answer_g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05xm-VaW8UQh"
   },
   "source": [
    "**h**) $Pr(R|D=d^1, G=g^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1738111658215,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "shjD8GIL8UZV",
    "outputId": "e7670a19-fbc2-4286-f4e2-8142369bb6ce"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|D=d1, G=g2)=[0.21148 0.78852]\n"
     ]
    }
   ],
   "source": [
    "Pr_RDG =  np.sum(joint[:,1:2,:,2:3,:] , axis=(0,1,3,4))\n",
    "Pr_DG =  np.sum(joint[:,1:2,:,2:3 ,:] , axis=(0,1,2,3,4))\n",
    "answer_h =  (Pr_RDG / Pr_DG).squeeze()   # TODO\n",
    "print(f\"Pr(R|D=d1, G=g2)={answer_h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i2ahKAj8Umu"
   },
   "source": [
    "i) $Pr(R|D=d^0, G=g^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1738111658968,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "2nLKd4c18UuA",
    "outputId": "2754c7a9-0f99-4957-89b6-01c1a578a107"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|D=d0, G=g2)=[0.24667 0.75333]\n"
     ]
    }
   ],
   "source": [
    "Pr_RDG =  np.sum(joint[:,0:1,:,2:3,:] , axis=(0,1,3,4))\n",
    "Pr_DG =  np.sum(joint[:,0:1,:,2:3 ,:] , axis=(0,1,2,3,4))\n",
    "answer_i =  (Pr_RDG / Pr_DG).squeeze()   # TODO\n",
    "print(f\"Pr(R|D=d0, G=g2)={answer_i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUc0EpO18eA-"
   },
   "source": [
    "j) $Pr(R|D=d^1, L=l^1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1738111659881,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "mgDLu0nJ8eM2",
    "outputId": "27537403-445c-4215-c103-2b34ddd5e132"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|D=d1, L=l1)=[0.2475 0.7525]\n"
     ]
    }
   ],
   "source": [
    "Pr_RDL =  np.sum(joint[:,1:2,:,:, 1:2] , axis=(0,1,3,4))\n",
    "Pr_DL =  np.sum(joint[:,1:2,:,: ,1:2] , axis=(0,1,2,3,4))\n",
    "answer_j =  (Pr_RDL / Pr_DL).squeeze() # TODO\n",
    "print(f\"Pr(R|D=d1, L=l1)={answer_j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2rCcDgyuo5c"
   },
   "source": [
    "k) $Pr(R|D=d^0, L=l^1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1738111660814,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "dpt2RPQqvHbj",
    "outputId": "938982b1-8990-4a9f-d6e9-74ddfcaa43a1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|D=d1, L=l1)=[0.2736 0.7264]\n"
     ]
    }
   ],
   "source": [
    "Pr_RDL =  np.sum(joint[:,0:1,:,:, 1:2] , axis=(0,1,3,4))\n",
    "Pr_DL =  np.sum(joint[:,0:1,:,: ,1:2] , axis=(0,1,2,3,4))\n",
    "answer_k =  (Pr_RDL / Pr_DL).squeeze() # TODO\n",
    "print(f\"Pr(R|D=d1, L=l1)={answer_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiHUsWItvL2p"
   },
   "source": [
    "l) $Pr(R|do(G=g^2))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1738111661640,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "ag5OS3B_vT35",
    "outputId": "57a08ec5-f665-4787-822c-c85fffb1534a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|do(G=g2))=[0.34 0.66]\n"
     ]
    }
   ],
   "source": [
    "joint_2 = Pr_L_given_G[:,:,:,2:3 ,:] * Pr_R_given_S * Pr_S * Pr_D\n",
    "answer_l =  np.sum(joint_2[:,:,:,:,:] , axis=(0,1,3,4)) # TODO\n",
    "print(f\"Pr(R|do(G=g2))={answer_l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm1JoSs51P6l"
   },
   "source": [
    "m) $Pr(R|G=g^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1738111662288,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "JtZ_-padMHJg",
    "outputId": "7140e0f7-0025-4260-f69c-10e687be4fe9"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 2, 2, 1, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "joint_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1738009801859,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "8lT5Bhwm1Vca",
    "outputId": "9e866395-f3ba-437a-de03-c891cbc3bdf5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R|G=g2)=[0.24515 0.75485]\n"
     ]
    }
   ],
   "source": [
    "Pr_RG =  np.sum(joint[:,:,:,2:3,:] , axis=(0,1,3,4))\n",
    "Pr_G2 =  np.sum(joint[:,:,:,2:3 ,:] , axis=(0,1,2,3,4))\n",
    "answer_m = (Pr_RG / Pr_G2).squeeze() # TODO\n",
    "print(f\"Pr(R|G=g2)={answer_m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yAntka31ZDh"
   },
   "source": [
    "n) $Pr(R)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1738009801859,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "3156HkiD1mNe",
    "outputId": "44d16fbc-2b84-4cac-8b2e-524202248642"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(R=[0.34 0.66]\n"
     ]
    }
   ],
   "source": [
    "answer_n = np.sum(Pr_R_given_S * Pr_S, axis=(0,1,3 ,4)) # TODO\n",
    "print(f\"Pr(R={answer_n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR0NIlpE1dni"
   },
   "source": [
    "o) $Pr(G|do(L=l^1))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738009801859,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "N_SfC2CJ1bb7",
    "outputId": "df012768-e5f2-424b-d23a-ab04e10ca549"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G|do(L=l1))=[0.204  0.2316 0.5644]\n"
     ]
    }
   ],
   "source": [
    "joint_3 = Pr_G_given_SD * Pr_S * Pr_D * Pr_R_given_S\n",
    "answer_o =  np.sum( joint_3, axis=(0,1,2,4))# TODO\n",
    "print(f\"Pr(G|do(L=l1))={answer_o}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac48SDKS1x8p"
   },
   "source": [
    "p) $Pr(G=1|L=l^1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JBIIfpDOHvy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738009801996,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "8dNsTqjJ11P3",
    "outputId": "50aa07b4-b547-4d14-c4e5-67df5d86ab66"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pr(G=1|L=l1)=0.13789900505510602\n"
     ]
    }
   ],
   "source": [
    "Pr_GL =  np.sum(joint[:,:,:,:,1:2] , axis=(0,1,2,4))\n",
    "Pr_L1 =  np.sum(joint[:,:,:,:,1:2] , axis=(0,1,2,3,4))\n",
    "\n",
    "answer_p = (Pr_GL / Pr_L1).squeeze()[1]  # TODO\n",
    "print(f\"Pr(G=1|L=l1)={answer_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpoOrxiaHV43"
   },
   "source": [
    "**Réponse:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqfqhDoL5CfA"
   },
   "source": [
    "# Partie 2 (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjIVlyRq5CjA"
   },
   "source": [
    "## Objectif\n",
    "\n",
    "L’objectif de la partie 2 du travail pratique est de permettre à l’étudiant de se familiariser avec l’apprentissage automatique via la régression logistique. Nous allons donc résoudre un problème de classification d'images en utilisant l’approche de descente du gradient (gradient descent) pour optimiser la log-vraisemblance négative (negative log-likelihood) comme fonction de perte.\n",
    "\n",
    "L'algorithme à implémenter est une variation de descente de gradient qui s’appelle l’algorithme de descente de gradient stochastique par mini-ensemble (mini-batch stochastic gradient descent).  Votre objectif est d’écrire un programme en Python pour optimiser les paramètres d’un modèle étant donné un ensemble de données d’apprentissage, en utilisant un ensemble de validation pour déterminer quand arrêter l'optimisation, et finalement de montrer la performance sur l’ensemble du test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFxYYRQJ5Cnb"
   },
   "source": [
    "## Théorie: la régression logistique et le calcul du gradient\n",
    "\n",
    "\n",
    "Il est possible d’encoder l’information concernant l’étiquetage avec des vecteurs multinomiaux (one-hot vectors), c.-à-d. un vecteur de zéros avec un seul 1 pour indiquer quand la classe $C=k$ dans la dimension $k$. Par exemple, le vecteur $\\mathbf{y}=[0, 1, 0, \\cdots, 0]^T$ représente la deuxième classe. Les caractéristiques (features) sont données par des vecteurs $\\mathbf{x}_i \\in \\mathbb{R}^{D}$. En définissant les paramètres de notre modèle comme : $\\mathbf{W}=[\\mathbf{w}_1, \\cdots, \\mathbf{w}_K]^T$ et $\\mathbf{b}=[b_1, b_2, \\cdots  b_K]^T$ et la fonction softmax comme fonction de sortie, on peut exprimer notre modèle sous la forme :\n",
    "\\begin{eqnarray}\n",
    "    p(\\mathbf{y}|\\mathbf{x})\n",
    "    &=& \\frac{\\exp(\\mathbf{y}^T \\mathbf{W} \\mathbf{x} + \\mathbf{y}^T \\mathbf{b})}{\\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} \\exp(\\mathbf{y}_k^T \\mathbf{W} \\mathbf{x} + \\mathbf{y}_k^T \\mathbf{b})}\n",
    "\\end{eqnarray}\n",
    "L'ensemble de données consiste de $n$ paires (label, input) de la forme $\\mathscr{D}:=(\\mathbf{\\tilde{y}}_i, \\mathbf{\\tilde{x}}_i)_{i=1}^n$, où nous utilisons l'astuce de redéfinir $\\mathbf{\\tilde{x}}_i = [\\mathbf{\\tilde{x}}_i^T 1]^T$ et nous redéfinissions la matrice de paramètres $\\boldsymbol{\\theta} \\in \\mathbb{R}^{K\\times(D+1)}$ (voir des notes de cours pour la relation entre $\\boldsymbol{\\theta}$ et $\\mathbf{W}$). Notre fonction de perte, la log-vraisemblance négative des données selon notre modèle est définie comme:\n",
    "\\begin{equation}\n",
    "    \\mathscr{L}\\big( \\boldsymbol{\\theta}, \\mathscr{D} \\big) := -\\log \\prod_{i=1}^N P(\\mathbf{\\tilde{y}}_i|\\mathbf{\\tilde{x}}_i; \\boldsymbol{\\theta})\n",
    "\\end{equation}\n",
    "Pour cette partie du TP, nous avons calculé pour vous le gradient de la fonction de perte par rapport par rapport aux paramètres du modèle:\n",
    "\\begin{eqnarray}\n",
    "    \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\mathscr{L}\\big( \\boldsymbol{\\theta}, \\mathscr{D} \\big)\n",
    "    &=& -\\sum_{i=1}^N \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\Bigg\\{\\log \\Bigg(\\frac{\\exp(\\mathbf{\\tilde{y}}_i^T \\boldsymbol{\\theta} \\mathbf{\\tilde{x}}_i)}{\\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} \\exp(\\mathbf{y}_k^T \\boldsymbol{\\theta} \\mathbf{\\tilde{x}}_i)} \\Bigg) \\Bigg\\} \\\\\n",
    "    &=& -\\sum_{i=1}^N \\left(\\mathbf{\\tilde{y}}_i \\mathbf{\\tilde{x}}^T_i- \\sum_{\\mathbf{y}_k \\in \\mathscr{Y}} P(\\mathbf{y}_k|\\mathbf{\\tilde{x}}_i,\\boldsymbol{\\theta}) \\mathbf{y}_k \\mathbf{\\tilde{x}}^T_i \\right) \\\\\n",
    "    &=& \\sum_{i=1}^N \\mathbf{\\hat{p}}_i \\mathbf{\\tilde{x}}^T_i - \\sum_{i=1}^N \\mathbf{\\tilde{y}}_i \\mathbf{\\tilde{x}}^T_i\n",
    "\\end{eqnarray}\n",
    "où $\\mathbf{\\hat{p}}_i$ est un vecteur de probabilités produit par le modèle pour l'exemple $\\mathbf{\\tilde{x}}_i$ et $\\mathbf{\\tilde{y}}_i$ est le vrai *label* pour ce même exemple.\n",
    "\n",
    "Finalement, il reste à discuter de l'évaluation du modèle. Pour la tâche d'intérêt, qui est une instance du problème de classification, il existe plusieurs métriques pour mesurer les performances du modèle la précision de classification, l'erreur de classification, le taux de faux/vrai positifs/négatifs, etc. Habituellement dans le contexte de l'apprentissage automatique, la précision est la plus commune.\n",
    "\n",
    "La précision est définie comme le rapport du nombre d'échantillons bien classés sur le nombre total d'échantillons à classer:\n",
    "$$\n",
    "\\tau_{acc} := \\frac{|\\mathscr{C}|}{|\\mathscr{D}|}\n",
    "$$\n",
    "où l'ensemble des échantillons bien classés $\\mathscr{C}$ est:\n",
    "$$\n",
    "\\mathscr{C} := \\lbrace (\\mathbf{x}, \\mathbf{y}) \\in \\mathscr{D} \\, | \\, \\underset{k}{\\arg\\max} \\, \\, P(\\cdot|\\mathbf{\\tilde{x}}_i; \\boldsymbol{\\theta})_k = \\underset{k}{\\arg\\max} \\, \\, \\tilde{y}_{i,k} \\rbrace\n",
    "$$\n",
    "En mots, il s'agit du sous-ensemble d'échantillons pour lesquels la classe la plus probable selon notre modèle correspond à la vraie classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffr5uSLRzkkY"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3wjjnIDGHZj"
   },
   "source": [
    "## Description des tâches\n",
    "\n",
    "#### 1. Code à compléter\n",
    "\n",
    "On vous demande de compléter l'extrait de code ci-dessous pour résoudre ce problème. Vous devez utiliser la librairie PyTorch cette partie du TP: https://pytorch.org/docs/stable/index.html. Mettez à jour les paramètres de votre modèle avec la descente par *mini-batch*. Exécutez des expériences avec trois différents ensembles: un ensemble d’apprentissages avec 90\\% des exemples (choisis au hasard), un ensemble de validation avec 10\\%. Utilisez uniquement l'ensemble de test pour obtenir votre meilleur résultat une fois que vous pensez avoir obtenu votre meilleure stratégie pour entraîner le modèle.\n",
    "\n",
    "#### 2. Rapport à rédiger\n",
    "\n",
    "Présentez vos résultats dans un rapport. Ce rapport devrait inclure:\n",
    "\n",
    "- **Recherche d'hyperparamètres:** Faites une recherche d'hyperparamètres pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000 pour des modèles entrainés avec SGD. Présentez dans un tableau la précision finale du modèle, sur l'*ensemble de validation*, pour ces différentes combinaisons d'hyperparamètres.\n",
    "\n",
    "- **Analyse du meilleur modèle:** Pour votre meilleur modèle, présentez deux figures montrant la progression de son apprentissage sur l'*ensembe d'entrainement et l'ensemble de validation*. La première figure montrant les courbes de log-vraisemblance négative moyenne après chaque epoch, la deuxième montrant la précision du modèle après chaque epoch. Finalement donnez la précision finale sur l'ensemble de test.\n",
    "\n",
    "- **Lire l'article de recherche -\n",
    "Adam**: a method for stochastic optimization. Kingma, D., \\& Ba, J. (2015). International Conference on Learning Representation (ICLR).\n",
    "https://arxiv.org/pdf/1412.6980.pdf. Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "L'objectif du TP est de vous faire implémenter la rétropropagation à la main. **Il est donc interdit d'utiliser les capacités de construction de modèles ou de différentiation automatique de pytorch -- par exemple, aucun appels à torch.nn, torch.autograd ou à la méthode .backward().** L'objectif est d'implémenter un modèle de classification logistique ainsi que son entainement en utilisant uniquement des opérations matricielles de base fournies par PyTorch e.g. torch.sum(), torch.matmul(), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQq0nDgZuMfs"
   },
   "source": [
    "## Fonctions fournies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-U_jhXT_0Cbs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738179866079,
     "user_tz": 300,
     "elapsed": 20870,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     }
    },
    "outputId": "a01fefcf-d97b-4e18-e2eb-7c4c217446f7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:01<00:00, 16.9MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 303kB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.51MB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.2MB/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fonctions pour charger les ensembles de donnees\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=1):\n",
    "  dataset = FashionMNIST(\"./dataset\", train=True,  download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "  dataset_test = FashionMNIST(\"./dataset\", train=False,  download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "  len_train = int(len(dataset) * (1.-val_percentage))\n",
    "  len_val = len(dataset) - len_train\n",
    "  dataset_train, dataset_val = random_split(dataset, [len_train, len_val])\n",
    "  data_loader_train = DataLoader(dataset_train, batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "  data_loader_val   = DataLoader(dataset_val, batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "  data_loader_test  = DataLoader(dataset_test, batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "  return data_loader_train, data_loader_val, data_loader_test\n",
    "\n",
    "def reshape_input(x, y):\n",
    "    x = x.view(-1, 784)\n",
    "    y = torch.FloatTensor(len(y), 10).zero_().scatter_(1,y.view(-1,1),1)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# call this once first to download the datasets\n",
    "_ = get_fashion_mnist_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9H5BnbgAOpio",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738179866079,
     "user_tz": 300,
     "elapsed": 2,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     }
    }
   },
   "outputs": [],
   "source": [
    "# simple logger to track progress during training\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.losses_train = []\n",
    "        self.losses_valid = []\n",
    "        self.accuracies_train = []\n",
    "        self.accuracies_valid = []\n",
    "\n",
    "    def log(self, accuracy_train=0, loss_train=0, accuracy_valid=0, loss_valid=0):\n",
    "        self.losses_train.append(loss_train)\n",
    "        self.accuracies_train.append(accuracy_train)\n",
    "        self.losses_valid.append(loss_valid)\n",
    "        self.accuracies_valid.append(accuracy_valid)\n",
    "\n",
    "    def plot_loss_and_accuracy(self, train=True, valid=True):\n",
    "\n",
    "        assert train and valid, \"Cannot plot accuracy because neither train nor valid.\"\n",
    "\n",
    "        figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2,\n",
    "                                            figsize=(12, 6))\n",
    "\n",
    "        if train:\n",
    "            ax1.plot(self.losses_train, label=\"Training\")\n",
    "            ax2.plot(self.accuracies_train, label=\"Training\")\n",
    "        if valid:\n",
    "            ax1.plot(self.losses_valid, label=\"Validation\")\n",
    "            ax1.set_title(\"CrossEntropy Loss\")\n",
    "            ax2.plot(self.accuracies_valid, label=\"Validation\")\n",
    "            ax2.set_title(\"Accuracy\")\n",
    "\n",
    "        for ax in figure.axes:\n",
    "            ax.set_xlabel(\"Epoch\")\n",
    "            ax.legend(loc='best')\n",
    "            ax.set_axisbelow(True)\n",
    "            ax.minorticks_on()\n",
    "            ax.grid(True, which=\"major\", linestyle='-')\n",
    "            ax.grid(True, which=\"minor\", linestyle='--', color='lightgrey', alpha=.4)\n",
    "\n",
    "    def print_last(self):\n",
    "        print(f\"Epoch {len(self.losses_train):2d}, \\\n",
    "                Train:loss={self.losses_train[-1]:.3f}, accuracy={self.accuracies_train[-1]*100:.1f}%, \\\n",
    "                Valid: loss={self.losses_valid[-1]:.3f}, accuracy={self.losses_valid[-1]*100:.1f}%\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAJ5iiRUZw3f"
   },
   "source": [
    "## Aperçu de l'ensemble de données FashionMnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 1729,
     "status": "ok",
     "timestamp": 1738179867807,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "fK-eNmc8Zv2d",
    "outputId": "d0136c21-8f77-4c50-8483-2ee89efe7117"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 750x400 with 10 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "def plot_samples():\n",
    "  a, _, _ = get_fashion_mnist_dataloaders()\n",
    "  num_row = 2\n",
    "  num_col = 5# plot images\n",
    "  num_images = num_row * num_col\n",
    "  fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "  for i, (x,y) in enumerate(a):\n",
    "      if i >= num_images:\n",
    "        break\n",
    "      ax = axes[i//num_col, i%num_col]\n",
    "      x = (x.numpy().squeeze() * 255).astype(int)\n",
    "      y = y.numpy()[0]\n",
    "      ax.imshow(x, cmap='gray')\n",
    "      ax.set_title(f\"Label: {y}\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "plot_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpZ8NK8_CAqW"
   },
   "source": [
    "## Fonctions à compléter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSc19WnyQsFv"
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred) :\n",
    "    # todo : nombre d'éléments à classifier.\n",
    "    card_D = len(y)\n",
    "\n",
    "    # todo : calcul du nombre d'éléments bien classifiés.\n",
    "    card_C = torch.sum(torch.argmax(y_pred, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "\n",
    "    # todo : calcul de la précision de classification.\n",
    "    acc = card_C/card_D\n",
    "\n",
    "    return acc, (card_C, card_D)\n",
    "\n",
    "def accuracy_and_loss_whole_dataset(data_loader, model):\n",
    "    cardinal = 0\n",
    "    loss     = 0.\n",
    "    n_accurate_preds  = 0.\n",
    "\n",
    "    for x, y in data_loader:\n",
    "        x, y = reshape_input(x, y)\n",
    "        y_pred                = model.forward(x)\n",
    "        xentrp                = cross_entropy(y, y_pred)\n",
    "        _, (n_acc, n_samples) = accuracy(y, y_pred)\n",
    "\n",
    "        cardinal = cardinal + n_samples\n",
    "        loss = loss + xentrp\n",
    "        n_accurate_preds  = n_accurate_preds + n_acc\n",
    "\n",
    "    loss = loss / float(cardinal)\n",
    "    acc  = n_accurate_preds / float(cardinal)\n",
    "\n",
    "    return acc, loss\n",
    "\n",
    "def cross_entropy(y, y_pred):\n",
    "    # todo : calcul de la valeur d'entropie croisée.\n",
    "    y_pred = torch.clamp(y_pred, min=1e-9, max=1.0)\n",
    "    loss = -torch.sum(y * torch.log(y_pred))\n",
    "    return loss.item()\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    # assurez vous que la fonction est numeriquement stable\n",
    "    # e.g. softmax(torch.tensor([[1000, 10000, 100000],]))\n",
    "\n",
    "    # todo : calcul des valeurs de softmax(x)\n",
    "    x_max = torch.max(x, dim=axis, keepdim=True)\n",
    "    x = x - x_max.values\n",
    "    exp_x = torch.exp(x)\n",
    "    values = exp_x / torch.sum(exp_x, dim=axis, keepdim=True)\n",
    "\n",
    "    return values\n",
    "\n",
    "def inputs_tilde(x, axis=-1):\n",
    "    # augments the inputs `x` with ones along `axis`\n",
    "    # todo : implémenter code ici.\n",
    "    ones_shape = list(x.shape)\n",
    "\n",
    "    ones_shape[axis] = 1\n",
    "    ones = torch.ones(ones_shape, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    # Concatenate the ones along the specified axis\n",
    "    x_tilde = torch.cat([x, ones], dim=axis)\n",
    "\n",
    "    return x_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1738009803718,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "n2OYf0XjzaS7",
    "outputId": "af2b52e4-9576-44cd-a3c7-e4324e43de62"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.46203550696372986"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "y = torch.tensor([\n",
    "    [1, 0, 0],  # Class 0 is the true label for the first sample\n",
    "    [0, 1, 0]   # Class 1 is the true label for the second sample\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Predicted probabilities (output of a softmax function)\n",
    "y_pred = torch.tensor([\n",
    "    [0.7, 0.2, 0.1],  # Model's prediction for the first sample\n",
    "    [0.05, 0.9, 0.05]   # Model's prediction for the second sample\n",
    "], dtype=torch.float32)\n",
    "\n",
    "cross_entropy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738009803718,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     },
     "user_tz": 300
    },
    "id": "J5hgSHw_jWVm",
    "outputId": "0bed9cc9-ba03-4e6c-8b1e-cceb2b26dd1d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "softmax(torch.tensor([1000, 100, 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ya7J-i89GHnp"
   },
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "    def __init__(self, num_features, num_classes):\n",
    "      self.params = torch.normal(0, 0.01, (num_features + 1, num_classes))\n",
    "\n",
    "      self.t = 0\n",
    "      self.m_t = 0 # pour Adam: moyennes mobiles du gradient\n",
    "      self.v_t = 0 # pour Adam: moyennes mobiles du carré du gradient\n",
    "\n",
    "    def forward(self, x):\n",
    "      # todo : implémenter calcul des outputs en fonction des inputs `x`.\n",
    "      inputs = inputs_tilde(x)\n",
    "      outputs = softmax(torch.matmul(inputs, self.params))\n",
    "      return outputs\n",
    "\n",
    "    def get_grads(self, y, y_pred, X):\n",
    "      # todo : implémenter calcul des gradients.\n",
    "      grads = inputs_tilde(X).T @ (y_pred - y)\n",
    "      return grads\n",
    "\n",
    "    def sgd_update(self, lr, grads):\n",
    "      # TODO : implémenter mise à jour des paramètres ici.\n",
    "      self.params -= lr * grads\n",
    "\n",
    "\n",
    "    def adam_update(self, lr, grads):\n",
    "      # TODO : implémenter mise à jour des paramètres ici.\n",
    "      B1 = 0.9\n",
    "      B2 = 0.999\n",
    "      eps = 1e-8\n",
    "      self.t += 1\n",
    "      self.m_t = 0.9 * self.m_t + 0.1 * grads\n",
    "      self.v_t = 0.999 * self.v_t + 0.001 * torch.square(grads)\n",
    "      m_hat = self.m_t / (1 - B1**self.t)\n",
    "      v_hat = self.v_t / (1 - B2**self.t)\n",
    "      self.params -= lr * m_hat / (torch.sqrt(v_hat) + eps)\n",
    "\n",
    "def train(model, lr=0.1, nb_epochs=10, sgd=True, data_loader_train=None, data_loader_val=None):\n",
    "    best_model = None\n",
    "    best_val_accuracy = 0\n",
    "    logger = Logger()\n",
    "\n",
    "    for epoch in range(nb_epochs+1):\n",
    "        # at epoch 0 evaluate random initial model\n",
    "        #   then for subsequent epochs, do optimize before evaluation.\n",
    "        #print(f\"epoch {epoch}\")\n",
    "        #print(data_loader_train)\n",
    "\n",
    "        if epoch > 0:\n",
    "          for x, y in data_loader_train:\n",
    "              x, y = reshape_input(x, y)\n",
    "              y_pred = model.forward(x)\n",
    "              loss = cross_entropy(y, y_pred)\n",
    "              grads = model.get_grads(y, y_pred, x)\n",
    "              if sgd:\n",
    "                model.sgd_update(lr, grads)\n",
    "              else:\n",
    "                model.adam_update(lr, grads)\n",
    "\n",
    "        accuracy_train, loss_train = accuracy_and_loss_whole_dataset(data_loader_train, model)\n",
    "        accuracy_val, loss_val = accuracy_and_loss_whole_dataset(data_loader_val, model)\n",
    "\n",
    "        if accuracy_val > best_val_accuracy:\n",
    "          best_val_accuracy = accuracy_val\n",
    "          best_model = model\n",
    "          #print(\"best model\")   # TODO : record the best model parameters and best validation accuracy\n",
    "\n",
    "        logger.log(accuracy_train, loss_train, accuracy_val, loss_val)\n",
    "        print(f\"Epoch {epoch:2d}, \\\n",
    "                Train: loss={loss_train:.3f}, accuracy={accuracy_train*100:.1f}%, \\\n",
    "                Valid: loss={loss_val:.3f}, accuracy={accuracy_val*100:.1f}%\", flush=True)\n",
    "\n",
    "    return best_model, best_val_accuracy, logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRtX_EXNQWoX"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "logger = Logger()\n",
    "model = LinearModel(num_features=784, num_classes=10)\n",
    "for x, y in data_loader_train:\n",
    "    #print(x.shape)\n",
    "    #print(y.shape)\n",
    "    x, y = reshape_input(x, y)\n",
    "\n",
    "    y_pred = model.forward(x)\n",
    "    loss = cross_entropy(y, y_pred)\n",
    "    grads = model.get_grads(y, y_pred, x)\n",
    "    model.sgd_update(0.1, grads)\n",
    "\n",
    "accuracy_train, loss_train = accuracy_and_loss_whole_dataset(data_loader_train, model)\n",
    "accuracy_val, loss_val = accuracy_and_loss_whole_dataset(data_loader_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zUGBmtf9pcA"
   },
   "source": [
    "## Évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUuU5n979pcD"
   },
   "source": [
    "### SGD: Recherche d'hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4R_6Rxgq9pcE",
    "outputId": "d3c34be4-b292-4f27-ac03-4570c07ff121"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------------\n",
      "Training model with a learning rate of 0.1 and a batch size of 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch  0,                 Train: loss=2.311, accuracy=3.5%,                 Valid: loss=2.312, accuracy=3.4%\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "# Montrez les résultats pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000.\n",
    "batch_size_list = [1,20 , 200 , 2000]   # Define ranges in a list\n",
    "lr_list = [0.1 ,  0.01 , 0.001 ]           # Define ranges in a list\n",
    "\n",
    "with torch.no_grad():\n",
    "  for lr in lr_list:\n",
    "    for batch_size in batch_size_list:\n",
    "      print(\"------------------------------------------------------------------\")\n",
    "      print(\"Training model with a learning rate of {0} and a batch size of {1}\".format(lr, batch_size))\n",
    "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "      model = LinearModel(num_features=784, num_classes=10)\n",
    "      _, val_accuracy, _ = train(model,lr=lr, nb_epochs=5, sgd=True, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmvtxoLo9pcF"
   },
   "source": [
    "#### **Tableau pour la précision sur l'ensemble de validation**\n",
    "N.B. que les lignes correspondent aux valeurs du taux d'apprentisage et les colonnes correspondent au valeur du batch size. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
    "\n",
    "learning rate\\batch_size  | 1 | 20 | 200 | 1000\n",
    "-------------------|------------------|------------------|------------------|------------------|\n",
    "**0.1**   | -  | - | - | - | - |\n",
    "**0.01** | -  | - | - | - | - |\n",
    "**0.001**  | -  | - | - | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PvrqlWt9pcG"
   },
   "source": [
    "### SGD: Analyse du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQ8Vc8JM9pcG"
   },
   "outputs": [],
   "source": [
    "# SGD\n",
    "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
    "batch_size = None # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "lr = None         # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "\n",
    "with torch.no_grad():\n",
    "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "  model = LinearModel(num_features=784, num_classes=10)\n",
    "  best_model, best_val_accuracy, logger = train(model,lr=lr, nb_epochs=5, sgd=True,\n",
    "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "  logger.plot_loss_and_accuracy()\n",
    "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
    "\n",
    "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
    "print(\"Evaluation of the best training model over test set\")\n",
    "print(\"------\")\n",
    "print(f\"Loss : {loss_test:.3f}\")\n",
    "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOZXfA919pcH"
   },
   "source": [
    "# Adam: Recherche d'hyperparamètres\n",
    "\n",
    "Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ze9D0Zpi9pcI"
   },
   "outputs": [],
   "source": [
    "# ADAM\n",
    "# Montrez les résultats pour différents taux d'apprentissage, e.g. 0.1, 0.01, 0.001, et différentes tailles de mini-batch, e.g. 1, 20, 200, 1000.\n",
    "batch_size_list = [1,20 , 200 , 2000]   # Define ranges in a list\n",
    "lr_list = [0.1 ,  0.01 , 0.001 ]\n",
    "\n",
    "with torch.no_grad():\n",
    "  for lr in lr_list:\n",
    "    for batch_size in batch_size_list:\n",
    "      print(\"------------------------------------------------------------------\")\n",
    "      print(\"Training model with a learning rate of {0} and a batch size of {1}\".format(lr, batch_size))\n",
    "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "      model = LinearModel(num_features=784, num_classes=10)\n",
    "      _, val_accuracy, _ = train(model,lr=lr, nb_epochs=5, sgd=False, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr9_MzpX_CvO"
   },
   "source": [
    "#### **Tableau pour la précision sur l'ensemble de validation**\n",
    "N.B. que les lignes correspondent aux valeurs du taux d'apprentisage et les colonnes correspondent au valeur du batch size. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
    "\n",
    "learning rate\\batch_size  | 1 | 20 | 200 | 1000\n",
    "-------------------|------------------|------------------|------------------|------------------|\n",
    "**0.1**   | -  | - | - | - | - |\n",
    "**0.01** | -  | - | - | - | - |\n",
    "**0.001**  | -  | - | - | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Me7IOblUrYw"
   },
   "source": [
    "### Adam: Analyse du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ndf_GP6XPV-U"
   },
   "outputs": [],
   "source": [
    "# ADAM\n",
    "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
    "batch_size = None # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "lr = None         # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "\n",
    "with torch.no_grad():\n",
    "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "  model = LinearModel(num_features=784, num_classes=10)\n",
    "  best_model, best_val_accuracy, logger = train(model,lr=lr, nb_epochs=5, sgd=False,\n",
    "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "  logger.plot_loss_and_accuracy()\n",
    "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
    "\n",
    "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
    "print(\"Evaluation of the best training model over test set\")\n",
    "print(\"------\")\n",
    "print(f\"Loss : {loss_test:.3f}\")\n",
    "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LRkxtUD_RVd"
   },
   "source": [
    "### Analyse des Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NIRJe-8_fbP"
   },
   "source": [
    "Répondez içi..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IficnxEMMcNo"
   },
   "source": [
    "# Partie 3 (20 points)\n",
    "\n",
    "Pour cette partie, vous pouvez travailler en groupes de 2, mais il faut écrire sa propre dérivation et soumettre son propre rapport. Si vous travaillez avec un partenaire, il faut indiquer leur nom dans votre rapport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zmb_putke8pl"
   },
   "source": [
    "### Problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRioLmIDMcP8"
   },
   "source": [
    "![picture](https://drive.google.com/uc?id=17_N7pIrf5pypQKiUh5cM7SX6raZUBcJC)\n",
    "\n",
    "Considérons maintenant un réseau de neurones avec une couche d'entrée avec $D=784$ unités, $L$ couches cachées, chacune avec 300 unités et un vecteur de sortie $\\mathbf{y}$ de dimension $K$. Vous avez $i = 1, .., N$ exemples dans un ensemble d'apprentissage, où chaque ${\\bf x}_i \\in \\mathbb{R}^{784}$ est un vecteur de caractéristiques (features). $\\mathbf{y}$ est un vecteur du type *one-hot* -- un vecteur de zéros avec un seul 1 pour indiquer que la classe $C=k$ dans la dimension $k$. Par exemple, le vecteur $\\mathbf{y}=[0, 1, 0, \\cdots, 0]^T$ représente la deuxième classe. La fonction de perte est donnée par\n",
    "\\begin{equation}\n",
    "\\mathscr{L} = -\\sum_{i=1}^{N}\\sum_{k=1}^{K}y_{k,i}\\log (f_k( {\\bf x}_i )  )\n",
    "\\end{equation}\n",
    "\n",
    "La fonction d'activation de la couche finale a la forme  ${\\bf f} = [f_1, ..., f_K]$ donné par la fonction d'activation softmax:\n",
    "\\begin{equation}\n",
    "f_k( {\\bf a}^{(L+1)}({\\bf x}_i) ) = \\frac{\\exp(a_k^{(L+1)})}{\\sum_{c=1}^{K}\\exp(a_c^{(L+1)})}, \\;\\;\\;\\;\n",
    "\\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "et les couches cachées utilisent une fonction d'activation de type ReLU:\n",
    "\\begin{equation}\n",
    "  {\\bf h}^{(l)}({\\bf a}^{(l)}({\\bf x}_i)) = \\text{ReLU}({\\bf a}^{(l)}({\\bf x}_i) = \\max\\Big(0, \\, \\, {\\bf a}^{(l)}({\\bf x}_i)\\Big)\n",
    "\\end{equation}\n",
    "\n",
    "où ${\\bf a}^{(l)}$ est le vecteur résultant du calcul de la préactivation habituelle ${\\bf a}^{(l)}={\\bf W}^{(l)}{\\bf h}^{(l-1)} + {\\bf b}^{(l)}$, qui pourrait être simplifiée à ${\\boldsymbol \\theta}^{(l)}\\tilde{\\bf h}^{(l-1)}$ en utilisant l'astuce de définir $\\tilde{\\bf h}$ comme ${\\bf h}$ avec un 1 concaténé à la fin du vecteur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzMpz3Zse0t9"
   },
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK8gnygxMcSh"
   },
   "source": [
    "* a) (10 points) Donnez le pseudocode incluant des *calculs matriciels—vectoriels* détaillés pour l'algorithme de rétropropagation pour calculer le gradient pour les paramètres de chaque couche **étant donné un exemple d'entraînement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y431_w4gMcX2"
   },
   "source": [
    "* b) (15 points)\n",
    "Implémentez l'optimisation basée sur le gradient de ce réseau en Pytorch.\n",
    "Utilisez le code squelette ci-dessous comme point de départ et implémentez les mathématiques de l'algorithme de rétropropagation que vous avez décrit à la question précédente. Comparez vos gradients et votre optimisation avec le même modèle optimisé avec Autograd. Lequel est le plus rapide ? Proposez quelques expériences. Utilisez encore l'ensemble de données de Fashion MNIST (voir Partie 2). **Comparez différents modèles ayant différentes largeurs (nombre d'unités) et profondeurs (nombre de couches)**. Ici encore, n'utilisez l'ensemble de test que pour votre expérience finale lorsque vous pensez avoir obtenu votre meilleur modèle.\n",
    "\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "L'objectif du TP est de vous faire implémenter la rétropropagation à la main. L'objectif est d'implémenter un modèle de classification logistique ainsi que son entainement en utilisant uniquement des opérations matricielles de base fournies par PyTorch e.g. torch.sum(), torch.matmul(), etc. **Une fois que vous avez implémenté votre modèle, vous devez le comparer avec un modèle construit en utilisant les capacités de pytorch qui permettent une différenciation automatique. Autrement dit, pour la deuxième implémentation, vous pouvez utilisertorch.nn, torch.autograd ou à la méthode .backward().** Vous pouvez utiliser l’implémentation de votre choix pour explorer différentes architectures de modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1mpuG2cwER-"
   },
   "source": [
    "## Votre pseudocode:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qY2X9goYwMDs"
   },
   "source": [
    "#### Algorithme de rétropopagation dans un réseau de neurones pour un exemple $\\tilde{x}_i$:\n",
    "\n",
    "1. TODO\n",
    "2. TODO\n",
    "3. TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modèle de Réseau de Neurones\n",
    "\n",
    "Soit les transformations suivantes dans un réseau de neurones avec 1 couche:\n",
    "\n",
    "1. **Entrée** :\n",
    "   $$\n",
    "   x = \\text{input}\n",
    "   $$\n",
    "\n",
    "2. **Première transformation linéaire** :\n",
    "   $$\n",
    "   z = W x + b_1\n",
    "   $$\n",
    "\n",
    "3. **Activation ReLU** :\n",
    "   $$\n",
    "   h = \\text{ReLU}(z)\n",
    "   $$\n",
    "\n",
    "4. **Deuxième transformation linéaire** :\n",
    "   $$\n",
    "   \\theta = U h + b_2\n",
    "   $$\n",
    "\n",
    "5. **Sortie avec softmax** :\n",
    "   $$\n",
    "   \\hat{y} = \\text{softmax}(\\theta)\n",
    "   $$\n",
    "\n",
    "6. **Fonction de coût (cross-entropy)** :\n",
    "   $$\n",
    "   J = CE(y, \\hat{y})\n",
    "   $$\n"
   ],
   "metadata": {
    "id": "pmarlZ7TsDmR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calcul du Gradient pour la Rétropropagation\n",
    "\n",
    "Nous allons calculer le gradient de la fonction de coût \\( J \\) par rapport aux paramètres \\( W \\) et \\( U \\) en utilisant la rétropropagation.\n",
    "\n",
    "## 1. Gradient de la fonction de perte\n",
    "\n",
    "La dérivée de la perte d'entropie croisée par rapport à la sortie du softmax est donnée par :\n",
    "\n",
    "$$\n",
    "\\delta = \\frac{\\partial J}{\\partial \\hat{y}} =  \\hat{y}\\ - y\n",
    "$$\n",
    "\n",
    "où :\n",
    "-  $y$ est la vraie étiquette,\n",
    "- $\\hat{y}$ est la sortie du réseau après le softmax.\n",
    "\n",
    "## 2. Calcul du Gradient des Paramètres des Couches\n",
    "\n",
    "Nous utilisons une boucle pour propager l'erreur en arrière et calculer les gradients.\n",
    "\n",
    "### Cas général pour les couches cachées :\n",
    "\n",
    "Pour une couche cachée \\( i \\), le gradient de la matrice de poids $W^{(i)}$ est donné par :\n",
    "\n",
    "$$\n",
    "\\nabla W^{(i)} = h^{(i-1) T} \\cdot \\delta^{(i)}\n",
    "$$\n",
    "\n",
    "où :\n",
    "-  $h^{(i-1)}$  est la sortie de la couche précédente (avec un biais ajouté),\n",
    "-  $\\delta^{(i)}$ est l'erreur transmise à la couche  i .\n",
    "\n",
    "Le terme **delta** est mis à jour en fonction de la couche précédente :\n",
    "\n",
    "$$\n",
    "\\delta^{(i-1)} = (\\delta^{(i)} \\cdot W^{(i) T}) \\odot \\text{ReLU}'(a^{(i-1)})\n",
    "$$\n",
    "\n",
    "où :\n",
    "-  $a^{(i-1)} $ est l'activation avant l'application de ReLU,\n",
    "-  ${ReLU}'(a) $ est la dérivée de ReLU.\n",
    "\n",
    "La dérivée de ReLU, notée **${\\text{ReLU}'}(x)$**, est donnée par :\n",
    "\n",
    "$$\n",
    "\\text{ReLU}'(x) =\n",
    "\\begin{cases}\n",
    "    1, & \\text{si } x > 0 \\\\\n",
    "    0, & \\text{si } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Cas particulier pour la couche d'entrée :\n",
    "\n",
    "Pour la première couche (\\( i = 0 \\)), le gradient est :\n",
    "\n",
    "$$\n",
    "\\nabla W^{(0)} = x^T \\cdot \\delta^{(0)}\n",
    "$$\n",
    "\n",
    "où \\( x \\) est l'entrée du réseau.\n",
    "\n",
    "## 3. Algorithme Complet\n",
    "\n",
    "- **Étape 1 :** Initialiser $\\delta$ avec la dérivée de l'entropie croisée.\n",
    "- **Étape 2 :** Pour chaque couche $i$, calculer $\\nabla W^{(i)}$ et mettre à jour $\\delta$.\n",
    "- **Étape 3 :** Retourner tous les gradients.\n",
    "\n",
    "\n",
    "Ce processus permet d'obtenir les gradients nécessaires à l'optimisation du réseau via des méthodes comme la descente de gradient.\n"
   ],
   "metadata": {
    "id": "uY_RZEaGtZWR"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIQJD-TRwEdo"
   },
   "source": [
    "## Fonctions à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIe9DFvPwuQg"
   },
   "source": [
    "## Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "''' Les fonctions dans cette cellule peuvent avoir les mêmes déclarations que celles de la partie 2'''\n",
    "def accuracy(y, y_pred) :\n",
    "    # todo : nombre d'éléments à classifier.\n",
    "    # todo : nombre d'éléments à classifier.\n",
    "    card_D = len(y)\n",
    "\n",
    "    # todo : calcul du nombre d'éléments bien classifiés.\n",
    "    card_C = torch.sum(torch.argmax(y_pred, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "\n",
    "    # todo : calcul de la précision de classification.\n",
    "    acc = card_C/card_D\n",
    "\n",
    "    return acc, (card_C, card_D)\n",
    "\n",
    "def accuracy_and_loss_whole_dataset(data_loader, model):\n",
    "    cardinal = 0\n",
    "    loss     = 0.\n",
    "    n_accurate_preds  = 0.\n",
    "\n",
    "    for x, y in data_loader:\n",
    "        x, y = reshape_input(x, y)\n",
    "        y_pred                = model.forward(x)\n",
    "        xentrp                = cross_entropy(y, y_pred)\n",
    "        _, (n_acc, n_samples) = accuracy(y, y_pred)\n",
    "\n",
    "        cardinal = cardinal + n_samples\n",
    "        loss     = loss + xentrp\n",
    "        n_accurate_preds  = n_accurate_preds + n_acc\n",
    "\n",
    "    loss = loss / float(cardinal)\n",
    "    acc  = n_accurate_preds / float(cardinal)\n",
    "\n",
    "    return acc, loss\n",
    "\n",
    "def inputs_tilde(x, axis=-1):\n",
    "    # augments the inputs `x` with ones along `axis`\n",
    "    # todo : implémenter code ici.\n",
    "    ones_shape = list(x.shape)\n",
    "\n",
    "    ones_shape[axis] = 1\n",
    "    ones = torch.ones(ones_shape, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    # Concatenate the ones along the specified axis\n",
    "    x_tilde = torch.cat([x, ones], dim=axis)\n",
    "\n",
    "    return x_tilde\n",
    "\n",
    "def cross_entropy(y, y_pred):\n",
    "    # todo : calcul de la valeur d'entropie croisée.\n",
    "    y_pred = torch.clamp(y_pred, min=1e-9, max=1.0)\n",
    "    loss = -torch.sum(y * torch.log(y_pred))\n",
    "    return loss\n",
    "\n",
    "def softmax(x, axis=-1): # x of size[batch_size , number of classes]\n",
    "    # assurez vous que la fonction est numeriquement stable\n",
    "    # e.g. softmax(torch.tensor([[1000, 10000, 100000],]))\n",
    "\n",
    "    # todo : calcul des valeurs de softmax(x)\n",
    "    x_max = torch.max(x, dim=axis, keepdim=True)\n",
    "    x = x - x_max.values\n",
    "    exp_x = torch.exp(x)\n",
    "    values = exp_x / torch.sum(exp_x, dim=axis, keepdim=True)\n",
    "    return values\n",
    "\n",
    "\n",
    "def softmax_cross_entropy_backward(y, y_pred):\n",
    "    # todo : calcul de la valeur du gradient de l'entropie croisée composée avec `softmax`\n",
    "    values = y_pred - y\n",
    "    return values\n",
    "\n",
    "def relu_forward(x): ##x of size [batch size, num_features]\n",
    "    # todo : calcul des valeurs de relu(x)\n",
    "    values = torch.max(torch.zeros_like(x), x)\n",
    "    return values\n",
    "\n",
    "def relu_backward(x): ##x of size [batch size, num_features]\n",
    "    # todo : calcul des valeurs du gradient de la fonction `relu`\n",
    "    values = torch.where(x > 0, torch.ones_like(x), torch.zeros_like(x))\n",
    "    return values\n",
    "\n",
    "\n",
    "# Model est une classe representant votre reseaux de neuronnes\n",
    "class MLPModel:\n",
    "    def __init__(self, n_features, n_hidden_features, n_hidden_layers, n_classes):\n",
    "        self.n_features        = n_features\n",
    "        self.n_hidden_features = n_hidden_features\n",
    "        self.n_hidden_layers   = n_hidden_layers\n",
    "        self.n_classes         = n_classes\n",
    "        self.params = []\n",
    "\n",
    "        # todo : initialiser la liste des paramètres Teta de l'estimateur.\n",
    "\n",
    "        for i in range(n_hidden_layers+1):\n",
    "            if i == 0:\n",
    "                self.params.append(torch.normal(0, 0.01, (n_features + 1, n_hidden_features)))\n",
    "            elif i == n_hidden_layers :\n",
    "              self.params.append(torch.normal(0, 0.01, (n_hidden_features + 1, n_classes)))\n",
    "            else:\n",
    "              self.params.append(torch.normal(0, 0.01, (n_hidden_features + 1, n_hidden_features)))\n",
    "        print(f\"Teta params={[p.shape for p in self.params]}\")\n",
    "\n",
    "        self.a = [] # liste contenant le resultat des multiplications matricielles\n",
    "        self.h = [] # liste contenant le resultat des fonctions d'activations\n",
    "\n",
    "        self.t = 0\n",
    "        self.m_t = 0 # pour Adam: moyennes mobiles du gradient\n",
    "        self.v_t = 0 # pour Adam: moyennes mobiles du carré du gradient\n",
    "\n",
    "    def forward(self, x):\n",
    "        # todo : implémenter calcul des outputs en fonction des inputs `x`.\n",
    "        self.a = []\n",
    "        self.h = []\n",
    "        inputs = inputs_tilde(x)\n",
    "        for i in range(self.n_hidden_layers+1):\n",
    "            if i == 0:\n",
    "              self.a.append(torch.matmul(inputs, self.params[i]))\n",
    "            else:\n",
    "              self.a.append(torch.matmul(self.h[i-1], self.params[i]))\n",
    "\n",
    "            if i == self.n_hidden_layers:\n",
    "              self.h.append(self.a[i])\n",
    "            else :\n",
    "              self.h.append(inputs_tilde(relu_forward(self.a[i])))\n",
    "\n",
    "        outputs = softmax(self.h[self.n_hidden_layers])\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def backward(self, y, y_pred,x):\n",
    "\n",
    "      grads = [None] * (self.n_hidden_layers + 1) # gradients pour les n_hiddens_layers + params de la dernière hidden layer à la couche ou on fait le softmax\n",
    "\n",
    "      # Step 1: Compute the gradient of the loss w.r.t. the output\n",
    "      delta = softmax_cross_entropy_backward(y, y_pred) ## début [batch_size , num_classes]\n",
    "\n",
    "      for i in range(self.n_hidden_layers, -1, -1):\n",
    "        #print(f\"Shape of inputs_tilde(x): {inputs_tilde(x).shape}\")\n",
    "        #print(f\"Shape of delta: {delta.shape}\")\n",
    "        #print(f\"Shape of params[{i}]: {self.params[i].shape}\")\n",
    "        #print(f\"Shape of a[{i}]: {self.a[i].shape}\")\n",
    "        #print(f\"Shape of h[{i}]: {self.h[i].shape}\")\n",
    "        if i != 0:\n",
    "            grads[i] = torch.matmul(self.h[i - 1].T, delta) # [n_hidden_features +1 , batch_size] * [batch_size , num_classes] for the first delta => [n_hidden_features +1 , num_classes] cohérent\n",
    "            #print(f\"Shape of grads[{i}]: {grads[i].shape}\")\n",
    "            # [n_hidden_features , batch_size] * [batch_size , n_hidden_features] => [n_hidden_features , n_hidden_features] after\n",
    "            # On calcule le delta pour l'itération d'après\n",
    "            #(le delta étant toute la multiplication matricielle utile pour le gradient)\n",
    "            delta = torch.matmul(delta, self.params[i].T)[:, :-1] * relu_backward(self.a[i-1]) # [batch_size , num_classes] * [num_classes , n_hidden_features+1] => [batch_size , n_hidden_features +1 -1 ] for the first iteration\n",
    "            # =>  [batch_size , n_hidden_features]\n",
    "            # [batch_size , n_hidden_features] * [n_hidden_features , n_hidden_features+1] => [batch_size , n_hidden_features +1 -1] for after\n",
    "        else:\n",
    "            grads[i] = torch.matmul(inputs_tilde(x).T, delta) # [n_features  ,batch_size] * [batch_size , n_hidden_features] => [n_features , n_hidden_features]\n",
    "        #print(f\"Shape of grads[{i}]: {grads[i].shape}\")\n",
    "      return grads\n",
    "\n",
    "\n",
    "\n",
    "    def sgd_update(self, lr, grads):\n",
    "        for i in range(self.n_hidden_layers+1) :\n",
    "          self.params[i] -= lr * grads[i]\n",
    "         # TODO : implémenter mise à jour des paramètres ici.\n",
    "\n",
    "    def adam_update(self, lr, grads):\n",
    "        # TODO : implémenter mise à jour des paramètres ici.\n",
    "        pass\n",
    "\n",
    "def train(model, lr=0.1, nb_epochs=10, sgd=True, data_loader_train=None, data_loader_val=None):\n",
    "    best_model = None\n",
    "    best_val_accuracy = 0\n",
    "    logger = Logger()\n",
    "\n",
    "    for epoch in range(nb_epochs+1):\n",
    "\n",
    "        # at epoch 0 evaluate random initial model\n",
    "        #   then for subsequent epochs, do optimize before evaluation.\n",
    "        if epoch > 0:\n",
    "            for x, y in data_loader_train:\n",
    "                x, y = reshape_input(x, y)\n",
    "\n",
    "                y_pred = model.forward(x)\n",
    "                grads  = model.backward(y, y_pred , x)\n",
    "                if sgd:\n",
    "                  model.sgd_update(lr, grads)\n",
    "                else:\n",
    "                  model.adam_update(lr, grads)\n",
    "\n",
    "        accuracy_train, loss_train = accuracy_and_loss_whole_dataset(data_loader_train, model)\n",
    "        accuracy_val, loss_val = accuracy_and_loss_whole_dataset(data_loader_val, model)\n",
    "\n",
    "        if accuracy_val > best_val_accuracy:\n",
    "          best_val_accuracy = accuracy_val\n",
    "          best_model = model\n",
    "             # TODO : record the best model parameters and best validation accuracy\n",
    "\n",
    "        logger.log(accuracy_train, loss_train, accuracy_val, loss_val)\n",
    "        print(f\"Epoch {epoch:2d}, \\\n",
    "                Train:loss={loss_train:.3f}, accuracy={accuracy_train*100:.1f}%, \\\n",
    "                Valid: loss={loss_val:.3f}, accuracy={accuracy_val*100:.1f}%\", flush=True)\n",
    "\n",
    "    return best_model, best_val_accuracy, logger"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml5jUvG9AUXK"
   },
   "source": [
    "### SGD: Recherche d'hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fe7hyN63AUXL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738185318491,
     "user_tz": 300,
     "elapsed": 3601741,
     "user": {
      "displayName": "mohamed ali lajnef",
      "userId": "08899341440052003904"
     }
    },
    "outputId": "77d25221-584d-4b3f-f787-bb7c0f1b76fd",
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------------\n",
      "Training model with a depth of 1 layers and a width of 25 units\n",
      "Teta params=[torch.Size([785, 25]), torch.Size([26, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=11.2%,                 Valid: loss=2.303, accuracy=11.8%\n",
      "Epoch  1,                 Train:loss=0.605, accuracy=78.1%,                 Valid: loss=0.591, accuracy=78.6%\n",
      "Epoch  2,                 Train:loss=0.478, accuracy=83.4%,                 Valid: loss=0.480, accuracy=82.8%\n",
      "Epoch  3,                 Train:loss=0.449, accuracy=84.1%,                 Valid: loss=0.454, accuracy=83.8%\n",
      "Epoch  4,                 Train:loss=0.417, accuracy=85.5%,                 Valid: loss=0.420, accuracy=85.5%\n",
      "Epoch  5,                 Train:loss=0.399, accuracy=86.0%,                 Valid: loss=0.408, accuracy=86.0%\n",
      "validation accuracy = 85.967\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 1 layers and a width of 100 units\n",
      "Teta params=[torch.Size([785, 100]), torch.Size([101, 10])]\n",
      "Epoch  0,                 Train:loss=2.301, accuracy=12.0%,                 Valid: loss=2.301, accuracy=11.6%\n",
      "Epoch  1,                 Train:loss=0.529, accuracy=81.9%,                 Valid: loss=0.547, accuracy=81.0%\n",
      "Epoch  2,                 Train:loss=0.448, accuracy=84.3%,                 Valid: loss=0.461, accuracy=84.2%\n",
      "Epoch  3,                 Train:loss=0.420, accuracy=85.0%,                 Valid: loss=0.432, accuracy=84.4%\n",
      "Epoch  4,                 Train:loss=0.387, accuracy=86.6%,                 Valid: loss=0.403, accuracy=86.0%\n",
      "Epoch  5,                 Train:loss=0.371, accuracy=86.8%,                 Valid: loss=0.394, accuracy=86.2%\n",
      "validation accuracy = 86.200\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 1 layers and a width of 300 units\n",
      "Teta params=[torch.Size([785, 300]), torch.Size([301, 10])]\n",
      "Epoch  0,                 Train:loss=2.302, accuracy=11.3%,                 Valid: loss=2.302, accuracy=11.3%\n",
      "Epoch  1,                 Train:loss=0.514, accuracy=82.2%,                 Valid: loss=0.531, accuracy=81.2%\n",
      "Epoch  2,                 Train:loss=0.494, accuracy=82.0%,                 Valid: loss=0.506, accuracy=81.5%\n",
      "Epoch  3,                 Train:loss=0.416, accuracy=85.0%,                 Valid: loss=0.429, accuracy=84.6%\n",
      "Epoch  4,                 Train:loss=0.392, accuracy=86.1%,                 Valid: loss=0.413, accuracy=85.2%\n",
      "Epoch  5,                 Train:loss=0.365, accuracy=87.2%,                 Valid: loss=0.386, accuracy=86.7%\n",
      "validation accuracy = 86.667\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 1 layers and a width of 500 units\n",
      "Teta params=[torch.Size([785, 500]), torch.Size([501, 10])]\n",
      "Epoch  0,                 Train:loss=2.304, accuracy=6.1%,                 Valid: loss=2.304, accuracy=6.2%\n",
      "Epoch  1,                 Train:loss=0.499, accuracy=82.9%,                 Valid: loss=0.516, accuracy=82.2%\n",
      "Epoch  2,                 Train:loss=0.440, accuracy=84.6%,                 Valid: loss=0.463, accuracy=84.0%\n",
      "Epoch  3,                 Train:loss=0.436, accuracy=84.1%,                 Valid: loss=0.466, accuracy=83.2%\n",
      "Epoch  4,                 Train:loss=0.400, accuracy=85.8%,                 Valid: loss=0.435, accuracy=85.0%\n",
      "Epoch  5,                 Train:loss=0.365, accuracy=87.2%,                 Valid: loss=0.405, accuracy=86.0%\n",
      "validation accuracy = 85.950\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 1 layers and a width of 1000 units\n",
      "Teta params=[torch.Size([785, 1000]), torch.Size([1001, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=16.8%,                 Valid: loss=2.304, accuracy=16.4%\n",
      "Epoch  1,                 Train:loss=0.509, accuracy=82.1%,                 Valid: loss=0.513, accuracy=81.7%\n",
      "Epoch  2,                 Train:loss=0.448, accuracy=84.2%,                 Valid: loss=0.455, accuracy=83.8%\n",
      "Epoch  3,                 Train:loss=0.413, accuracy=85.4%,                 Valid: loss=0.428, accuracy=84.8%\n",
      "Epoch  4,                 Train:loss=0.370, accuracy=87.0%,                 Valid: loss=0.389, accuracy=85.7%\n",
      "Epoch  5,                 Train:loss=0.380, accuracy=86.5%,                 Valid: loss=0.406, accuracy=85.4%\n",
      "validation accuracy = 85.683\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 3 layers and a width of 25 units\n",
      "Teta params=[torch.Size([785, 25]), torch.Size([26, 25]), torch.Size([26, 25]), torch.Size([26, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.9%\n",
      "Epoch  1,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.3%\n",
      "Epoch  2,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "Epoch  3,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.4%\n",
      "Epoch  4,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "Epoch  5,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "validation accuracy = 10.433\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 3 layers and a width of 100 units\n",
      "Teta params=[torch.Size([785, 100]), torch.Size([101, 100]), torch.Size([101, 100]), torch.Size([101, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=9.9%,                 Valid: loss=2.302, accuracy=10.7%\n",
      "Epoch  1,                 Train:loss=2.303, accuracy=10.1%,                 Valid: loss=2.303, accuracy=9.5%\n",
      "Epoch  2,                 Train:loss=2.301, accuracy=10.1%,                 Valid: loss=2.301, accuracy=9.5%\n",
      "Epoch  3,                 Train:loss=1.048, accuracy=58.0%,                 Valid: loss=1.039, accuracy=58.8%\n",
      "Epoch  4,                 Train:loss=0.719, accuracy=74.4%,                 Valid: loss=0.704, accuracy=75.2%\n",
      "Epoch  5,                 Train:loss=0.614, accuracy=77.8%,                 Valid: loss=0.603, accuracy=78.0%\n",
      "validation accuracy = 78.050\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 3 layers and a width of 300 units\n",
      "Teta params=[torch.Size([785, 300]), torch.Size([301, 300]), torch.Size([301, 300]), torch.Size([301, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.9%\n",
      "Epoch  1,                 Train:loss=1.119, accuracy=54.8%,                 Valid: loss=1.123, accuracy=54.6%\n",
      "Epoch  2,                 Train:loss=0.842, accuracy=70.2%,                 Valid: loss=0.833, accuracy=69.8%\n",
      "Epoch  3,                 Train:loss=0.557, accuracy=80.6%,                 Valid: loss=0.562, accuracy=80.7%\n",
      "Epoch  4,                 Train:loss=0.584, accuracy=77.9%,                 Valid: loss=0.597, accuracy=77.4%\n",
      "Epoch  5,                 Train:loss=0.407, accuracy=85.5%,                 Valid: loss=0.418, accuracy=85.1%\n",
      "validation accuracy = 85.067\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 3 layers and a width of 500 units\n",
      "Teta params=[torch.Size([785, 500]), torch.Size([501, 500]), torch.Size([501, 500]), torch.Size([501, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.302, accuracy=10.0%\n",
      "Epoch  1,                 Train:loss=0.848, accuracy=67.9%,                 Valid: loss=0.838, accuracy=68.4%\n",
      "Epoch  2,                 Train:loss=0.610, accuracy=77.1%,                 Valid: loss=0.600, accuracy=77.7%\n",
      "Epoch  3,                 Train:loss=0.462, accuracy=83.8%,                 Valid: loss=0.465, accuracy=83.9%\n",
      "Epoch  4,                 Train:loss=0.405, accuracy=85.5%,                 Valid: loss=0.419, accuracy=85.0%\n",
      "Epoch  5,                 Train:loss=0.430, accuracy=84.2%,                 Valid: loss=0.439, accuracy=83.8%\n",
      "validation accuracy = 85.017\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 3 layers and a width of 1000 units\n",
      "Teta params=[torch.Size([785, 1000]), torch.Size([1001, 1000]), torch.Size([1001, 1000]), torch.Size([1001, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=6.9%,                 Valid: loss=2.302, accuracy=6.7%\n",
      "Epoch  1,                 Train:loss=0.725, accuracy=71.5%,                 Valid: loss=0.755, accuracy=70.4%\n",
      "Epoch  2,                 Train:loss=0.481, accuracy=83.0%,                 Valid: loss=0.511, accuracy=81.7%\n",
      "Epoch  3,                 Train:loss=0.423, accuracy=84.8%,                 Valid: loss=0.446, accuracy=83.8%\n",
      "Epoch  4,                 Train:loss=0.377, accuracy=86.2%,                 Valid: loss=0.401, accuracy=85.4%\n",
      "Epoch  5,                 Train:loss=0.333, accuracy=88.0%,                 Valid: loss=0.363, accuracy=87.1%\n",
      "validation accuracy = 87.050\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 5 layers and a width of 25 units\n",
      "Teta params=[torch.Size([785, 25]), torch.Size([26, 25]), torch.Size([26, 25]), torch.Size([26, 25]), torch.Size([26, 25]), torch.Size([26, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "Epoch  1,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.2%\n",
      "Epoch  2,                 Train:loss=2.303, accuracy=9.9%,                 Valid: loss=2.303, accuracy=10.5%\n",
      "Epoch  3,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.1%\n",
      "Epoch  4,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.1%\n",
      "Epoch  5,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.3%\n",
      "validation accuracy = 10.550\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 5 layers and a width of 100 units\n",
      "Teta params=[torch.Size([785, 100]), torch.Size([101, 100]), torch.Size([101, 100]), torch.Size([101, 100]), torch.Size([101, 100]), torch.Size([101, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.1%\n",
      "Epoch  1,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "Epoch  2,                 Train:loss=2.303, accuracy=10.1%,                 Valid: loss=2.303, accuracy=9.5%\n",
      "Epoch  3,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "Epoch  4,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.1%\n",
      "Epoch  5,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "validation accuracy = 10.050\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 5 layers and a width of 300 units\n",
      "Teta params=[torch.Size([785, 300]), torch.Size([301, 300]), torch.Size([301, 300]), torch.Size([301, 300]), torch.Size([301, 300]), torch.Size([301, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "Epoch  1,                 Train:loss=2.303, accuracy=10.1%,                 Valid: loss=2.303, accuracy=9.4%\n",
      "Epoch  2,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.0%\n",
      "Epoch  3,                 Train:loss=2.303, accuracy=10.1%,                 Valid: loss=2.303, accuracy=9.4%\n",
      "Epoch  4,                 Train:loss=2.303, accuracy=10.1%,                 Valid: loss=2.303, accuracy=9.4%\n",
      "Epoch  5,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.0%\n",
      "validation accuracy = 10.000\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 5 layers and a width of 500 units\n",
      "Teta params=[torch.Size([785, 500]), torch.Size([501, 500]), torch.Size([501, 500]), torch.Size([501, 500]), torch.Size([501, 500]), torch.Size([501, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.2%\n",
      "Epoch  1,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.7%\n",
      "Epoch  2,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.7%\n",
      "Epoch  3,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=10.2%\n",
      "Epoch  4,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.8%\n",
      "Epoch  5,                 Train:loss=2.303, accuracy=10.1%,                 Valid: loss=2.303, accuracy=9.5%\n",
      "validation accuracy = 10.150\n",
      "------------------------------------------------------------------\n",
      "Training model with a depth of 5 layers and a width of 1000 units\n",
      "Teta params=[torch.Size([785, 1000]), torch.Size([1001, 1000]), torch.Size([1001, 1000]), torch.Size([1001, 1000]), torch.Size([1001, 1000]), torch.Size([1001, 10])]\n",
      "Epoch  0,                 Train:loss=2.303, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.6%\n",
      "Epoch  1,                 Train:loss=2.302, accuracy=10.0%,                 Valid: loss=2.303, accuracy=9.6%\n",
      "Epoch  2,                 Train:loss=2.283, accuracy=19.7%,                 Valid: loss=2.283, accuracy=20.2%\n",
      "Epoch  3,                 Train:loss=0.943, accuracy=63.6%,                 Valid: loss=0.944, accuracy=64.0%\n",
      "Epoch  4,                 Train:loss=0.632, accuracy=75.7%,                 Valid: loss=0.615, accuracy=75.8%\n",
      "Epoch  5,                 Train:loss=0.480, accuracy=83.1%,                 Valid: loss=0.492, accuracy=82.6%\n",
      "validation accuracy = 82.600\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "# Montrez les résultats pour différents nombre de couche, e.g. 1, 3, 5, et différent nombres de neurone, e.g. 25, 100, 300, 500, 1000.\n",
    "depth_list = [1,3,5]   # Define ranges in a list\n",
    "width_list = [25,100,300,500,1000]   # Define ranges in a list\n",
    "lr = 0.001           # Some value\n",
    "batch_size = 20   # Some value\n",
    "\n",
    "with torch.no_grad():\n",
    "  for depth in depth_list:\n",
    "    for width in width_list:\n",
    "      print(\"------------------------------------------------------------------\")\n",
    "      print(\"Training model with a depth of {0} layers and a width of {1} units\".format(depth, width))\n",
    "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "      MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
    "      _, val_accuracy, _ = train(MLP_model,lr=lr, nb_epochs=5, sgd=True, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnDMqFapAUXM"
   },
   "source": [
    "#### **Tableau pour la précision sur l'ensemble de validation**\n",
    "N.B. que les lignes correspondent aux nombre de couche et les colonnes correspondent au nombre de neurone dans chaque couche. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
    "\n",
    "depth\\width  | 25 | 100 | 300 | 500 | 1000\n",
    "-------------------|------------------|------------------|------------------|------------------|------------------|\n",
    "**1**   | -  | - | - | - | - |\n",
    "**3** | -  | - | - | - | - |\n",
    "**5**  | -  | - | - | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wuN-uw7AUXN"
   },
   "source": [
    "### SGD: Analyse du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CShZ3VB0AUXN"
   },
   "outputs": [],
   "source": [
    "# SGD\n",
    "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
    "depth = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "width = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "lr = None           # Some value\n",
    "batch_size = None   # Some value\n",
    "\n",
    "with torch.no_grad():\n",
    "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "  MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
    "  best_model, best_val_accuracy, logger = train(MLP_model,lr=lr, nb_epochs=5, sgd=True,\n",
    "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "  logger.plot_loss_and_accuracy()\n",
    "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
    "\n",
    "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
    "print(\"Evaluation of the best training model over test set\")\n",
    "print(\"------\")\n",
    "print(f\"Loss : {loss_test:.3f}\")\n",
    "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tPLgZriAUXO"
   },
   "source": [
    "### Adam: Recherche d'hyperparamètres\n",
    "\n",
    "Implémentez Adam, répétez les deux étapes précédentes (recherche d'hyperparamètres et analyse du meilleur modèle) cette fois en utilisat Adam, et comparez les performances finales avec votre meilleur modèle SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEVOh1r7AUXO"
   },
   "outputs": [],
   "source": [
    "# ADAM\n",
    "# Montrez les résultats pour différents nombre de couche, e.g. 1, 3, 5, et différent nombres de neurone, e.g. 25, 100, 300, 500, 1000.\n",
    "depth_list = [1,3,5]   # Define ranges in a list\n",
    "width_list = [25,100,300,500,1000]   # Define ranges in a list\n",
    "lr = None           # Some value\n",
    "batch_size = None   # Some value\n",
    "\n",
    "with torch.no_grad():\n",
    "  for depth in depth_list:\n",
    "    for width in width_list:\n",
    "      print(\"------------------------------------------------------------------\")\n",
    "      print(\"Training model with a depth of {0} layers and a width of {1} units\".format(depth, width))\n",
    "      data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "      MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
    "      _, val_accuracy, _ = train(MLP_model, lr=lr, nb_epochs=5, sgd=False, data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "      print(f\"validation accuracy = {val_accuracy*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LQ6q18CAUXP"
   },
   "source": [
    "#### **Tableau pour la précision sur l'ensemble de validation**\n",
    "N.B. que les lignes correspondent aux nombre de couche et les colonnes correspondent au nombre de neurone dans chaque couche. Les valeurs ci-dessous sont donné comme exemples; remplacez-les par les valeurs que vous avez utilisées pour votre recherche d'hyperparamètres.\n",
    "\n",
    "depth\\width  | 25 | 100 | 300 | 500 | 1000\n",
    "-------------------|------------------|------------------|------------------|------------------|------------------|\n",
    "**1**   | -  | - | - | - | - |\n",
    "**3** | -  | - | - | - | - |\n",
    "**5**  | -  | - | - | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df6Y9ziXAUXP"
   },
   "source": [
    "### Adam: Analyse du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uohnWTtoAUXP"
   },
   "outputs": [],
   "source": [
    "# ADAM\n",
    "# Montrez les résultats pour la meilleure configuration trouvez ci-dessus.\n",
    "depth = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "width = None    # TODO: Vous devez modifier cette valeur avec la meilleur que vous avez eu.\n",
    "lr = None           # Some value\n",
    "batch_size = None   # Some value\n",
    "\n",
    "with torch.no_grad():\n",
    "  data_loader_train, data_loader_val, data_loader_test = get_fashion_mnist_dataloaders(val_percentage=0.1, batch_size=batch_size)\n",
    "\n",
    "  MLP_model = MLPModel(n_features=784, n_hidden_features=width, n_hidden_layers=depth, n_classes=10)\n",
    "  best_model, best_val_accuracy, logger = train(MLP_model,lr=lr, nb_epochs=5, sgd=False,\n",
    "                                                data_loader_train=data_loader_train, data_loader_val=data_loader_val)\n",
    "  logger.plot_loss_and_accuracy()\n",
    "  print(f\"Best validation accuracy = {best_val_accuracy*100:.3f}\")\n",
    "\n",
    "  accuracy_test, loss_test = accuracy_and_loss_whole_dataset(data_loader_test, best_model)\n",
    "print(\"Evaluation of the best training model over test set\")\n",
    "print(\"------\")\n",
    "print(f\"Loss : {loss_test:.3f}\")\n",
    "print(f\"Accuracy : {accuracy_test*100.:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wlDcZB-AUXP"
   },
   "source": [
    "### Analyse des Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-Wi3CG3AUXP"
   },
   "source": [
    "Répondez içi..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "18wBEYJRamoyapvGntxqFqpaOPLX1swpI",
     "timestamp": 1737574942973
    },
    {
     "file_id": "1MXOh6MvEHoWrQRMHXRKaO6PFZfO9VEEa",
     "timestamp": 1736219514108
    },
    {
     "file_id": "19UqMDsk3lROmt9C8gZ6_Y624G3oufHTI",
     "timestamp": 1673805837437
    },
    {
     "file_id": "1TGtDS-d9nZkwuj8BWk75Sdr-cmldPm9R",
     "timestamp": 1641832158235
    },
    {
     "file_id": "1z_N5z6fABd2DBE-Y_kW4G5zgAoSk9eot",
     "timestamp": 1613146805025
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
